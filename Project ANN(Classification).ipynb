{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler , OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"E202-COMP7117-TD01-00 - classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ganti value dataset yang perlu diganti\n",
    "\n",
    "for i in range(0,dataset.shape[0]):\n",
    "    #Free Sulfure Dioxide\n",
    "    if dataset['free sulfur dioxide'].astype(str).str.contains('High').any() == True:\n",
    "        dataset[\"free sulfur dioxide\"] = dataset[\"free sulfur dioxide\"].replace('High', 3)\n",
    "    if dataset['free sulfur dioxide'].astype(str).str.contains('Medium').any() == True:\n",
    "        dataset[\"free sulfur dioxide\"] = dataset[\"free sulfur dioxide\"].replace('Medium', 2)\n",
    "    if dataset['free sulfur dioxide'].astype(str).str.contains('Low').any() == True:\n",
    "        dataset[\"free sulfur dioxide\"] = dataset[\"free sulfur dioxide\"].replace('Low', 1)\n",
    "    if dataset['free sulfur dioxide'].astype(str).str.contains('Unknown').any() == True:\n",
    "        dataset[\"free sulfur dioxide\"] = dataset[\"free sulfur dioxide\"].replace('Unknown', 0)\n",
    "    #Density\n",
    "    if dataset['density'].astype(str).str.contains('Very High').any() == True:\n",
    "        dataset[\"density\"] = dataset[\"density\"].replace('Very High', 0)\n",
    "    if dataset['density'].astype(str).str.contains('High').any() == True:\n",
    "        dataset[\"density\"] = dataset[\"density\"].replace('High', 3)\n",
    "    if dataset['density'].astype(str).str.contains('Medium').any() == True:\n",
    "        dataset[\"density\"] = dataset[\"density\"].replace('Medium', 2)\n",
    "    if dataset['density'].astype(str).str.contains('Low').any() == True:\n",
    "        dataset[\"density\"] = dataset[\"density\"].replace('Low', 1)\n",
    "    #pH\n",
    "    if dataset['pH'].astype(str).str.contains('Very Basic').any() == True:\n",
    "        dataset[\"pH\"] = dataset[\"pH\"].replace('Very Basic', 3)\n",
    "    if dataset['pH'].astype(str).str.contains('Normal').any() == True:\n",
    "        dataset[\"pH\"] = dataset[\"pH\"].replace('Normal', 2)\n",
    "    if dataset['pH'].astype(str).str.contains('Very Accidic').any() == True:\n",
    "        dataset[\"pH\"] = dataset[\"pH\"].replace('Very Accidic', 1)\n",
    "    if dataset['pH'].astype(str).str.contains('Unknown').any() == True:\n",
    "        dataset[\"pH\"] = dataset[\"pH\"].replace('Unknown', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize dataset\n",
    "from sklearn import preprocessing\n",
    "#print(dataset.shape)\n",
    "x = dataset[[\"volatile acidity\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]]\n",
    "y = dataset[\"quality\"]\n",
    "x = preprocessing.normalize(x)\n",
    "#print(normalize_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      principal component 1  principal component 2  principal component 3  \\\n",
      "0                 -0.054522              -0.016019              -0.055101   \n",
      "1                 -0.188804               0.018730              -0.005567   \n",
      "2                 -0.150314               0.004192              -0.027173   \n",
      "3                 -0.174261               0.007311               0.020155   \n",
      "4                 -0.054522              -0.016019              -0.055101   \n",
      "...                     ...                    ...                    ...   \n",
      "1594              -0.106580              -0.002811               0.017126   \n",
      "1595              -0.121920              -0.001330               0.015396   \n",
      "1596              -0.070662              -0.012096              -0.000192   \n",
      "1597              -0.109109              -0.002398               0.010591   \n",
      "1598              -0.079888              -0.017005               0.002301   \n",
      "\n",
      "      principal component 4 quality  \n",
      "0                  0.006513  Decent  \n",
      "1                  0.030106  Decent  \n",
      "2                  0.008729  Decent  \n",
      "3                 -0.013902    Fine  \n",
      "4                  0.006513  Decent  \n",
      "...                     ...     ...  \n",
      "1594               0.004849  Decent  \n",
      "1595               0.003700    Fine  \n",
      "1596               0.017239    Fine  \n",
      "1597               0.000791  Decent  \n",
      "1598              -0.020989    Fine  \n",
      "\n",
      "[1599 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Analisa dengan PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "principalComponent = pca.fit_transform(x)\n",
    "\n",
    "principalA = pd.DataFrame(data = principalComponent, columns=['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4'])\n",
    "finalA = pd.concat([principalA, dataset[['quality']]], axis = 1)\n",
    "print(finalA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch: 0, Current Error: 0.13448990881443024\n",
      "Epoch: 100, Current Error: 0.10606434941291809\n",
      "Epoch: 200, Current Error: 0.09002487361431122\n",
      "Epoch: 300, Current Error: 0.0809633880853653\n",
      "Epoch: 400, Current Error: 0.07566513866186142\n",
      "Epoch: 500, Current Error: 0.07246353477239609\n",
      "Saving....\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    feature = finalA[['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4']]\n",
    "    target = finalA[['quality']]\n",
    "    return feature, target\n",
    "\n",
    "feature, target = load_dataset()\n",
    "\n",
    "layer = {\n",
    "    'input' : 4,\n",
    "    'hidden' : 2,\n",
    "    'output' : 5\n",
    "}\n",
    "\n",
    "weight = {\n",
    "    'input_to_hidden' : tf.Variable(tf.random_normal([layer['input'], layer['hidden']])),\n",
    "    'hidden_to_output' : tf.Variable(tf.random_normal([layer['hidden'], layer['output']])) \n",
    "}\n",
    "bias = {\n",
    "    'input_to_hidden' : tf.Variable(tf.random_normal([layer['hidden']])),\n",
    "    'hidden_to_output' : tf.Variable(tf.random_normal([layer['output']]))\n",
    "}\n",
    "\n",
    "feature = OrdinalEncoder().fit_transform(feature)\n",
    "feature = MinMaxScaler().fit_transform(feature)\n",
    "\n",
    "target = OneHotEncoder(sparse=False).fit_transform(target)\n",
    "\n",
    "input_placeholder = tf.placeholder(tf.float32, [None, layer['input']])\n",
    "output_placeholder = tf.placeholder(tf.float32, [None, layer['output']])\n",
    "\n",
    "def feed_forward(dataset):\n",
    "    weightxbias1 = tf.matmul(dataset, weight['input_to_hidden']) + bias['input_to_hidden']\n",
    "    activation1 = tf.nn.sigmoid(weightxbias1)\n",
    "\n",
    "    weightxbias2 = tf.matmul(activation1, weight['hidden_to_output']) + bias['hidden_to_output']\n",
    "    activation2 = tf.nn.sigmoid(weightxbias2)\n",
    "\n",
    "    return activation2\n",
    "\n",
    "learning_rate = 0.2\n",
    "epoch = 5000\n",
    "\n",
    "output = feed_forward(input_placeholder)\n",
    "mse = tf.reduce_mean(0.5 * (output - output_placeholder) ** 2) \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(mse)\n",
    "saver = tf.train.Saver()\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(feature,target,test_size=0.3)\n",
    "feature2_test, vali_feature, target2_test, vali_target = train_test_split(feature_test,target_test,test_size=0.33)\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    feed_train = {\n",
    "        input_placeholder: feature_train,\n",
    "        output_placeholder: target_train\n",
    "    }\n",
    "    \n",
    "    feed_vali = {\n",
    "        input_placeholder: vali_feature,\n",
    "        output_placeholder: vali_target\n",
    "    }\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        sess.run(train, feed_dict=feed_train)\n",
    "        error = sess.run(mse, feed_dict = feed_train)\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: {}, Current Error: {}'. format(i+100, error))\n",
    "            \n",
    "        if i % 500 == 0 and i != 0:\n",
    "            val_error = sess.run(mse, feed_dict = feed_vali)\n",
    "            #print('Validation Error: {}'.format(val_error))\n",
    "            if i == 500 :\n",
    "                print(\"Saving....\")\n",
    "                saver.save(sess, \"my-model/model.ckpt\")\n",
    "                val_error_prev = val_error\n",
    "                #print(val_error_prev)\n",
    "                print(\"Save Successfully!\")\n",
    "            if i > 500:\n",
    "                print('Previous Validation Error: {}, Current Validation Error: {}'. format(val_error_prev, val_error))\n",
    "                if val_error < val_error_prev:\n",
    "                    print(\"Saving....\")\n",
    "                    saver.save(sess, \"my-model/model.ckpt\")\n",
    "                    val_error_prev = 0\n",
    "                    val_error_prev = val_error\n",
    "                    print(\"Save Successfully!\")\n",
    "                if val_error > val_error_prev:\n",
    "                    print('Current Validation Error is bigger!')\n",
    "                       \n",
    "    feed_test = {\n",
    "        input_placeholder: feature2_test,\n",
    "        output_placeholder: target2_test\n",
    "    }\n",
    "    \n",
    "    matches = tf.equal(tf.argmax(output, axis=1),tf.argmax(output_placeholder,axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "    print('Accuracy: {}%'.format(sess.run(accuracy*100, feed_dict =feed_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
